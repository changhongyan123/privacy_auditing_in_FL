common_args:
  training_type: "simulation"
  random_seed: 0

data_args:
  dataset: "cifar100"
  train_num: 2500
  pop_num: 1000
  test_num: 2500
  dirichlet_alpha: 0.5
  partitioning: "iid"
  data_argu: "no" # strong, standard, no

model_args:
  model: "resnet56"
  group_norm_channels: 32

train_args:
  federated_optimizer: "FedAvg"
  client_id_list: "[]"
  client_num_in_total: 4
  client_num_per_round: 4
  num_parties: 4
  train_batch_size: 64
  test_batch_size: 1000
  comm_round: 100 # 3 is for quick GitHub sanity check. please change this to your own hyper-parameters (e.g., 200)
  epochs: 20
  batch_size: 64
  client_optimizer: adam
  learning_rate: 0.001
  weight_decay: 0.0001

validation_args:
  frequency_of_the_test: 5

# device_args:
#   using_gpu: true
#   gpu_id: 7
device_args:
  worker_num: 5
  using_gpu: true
  gpu_mapping_file: gpu_mapping.yaml
  gpu_mapping_key: mapping_default

comm_args:
  backend: "MPI"
  is_mobile: 0

tracking_args:
  enable_tracking: false
  # When running on MLOps platform(open.fedml.ai), the default log path is at ~/fedml-client/fedml/logs/ and ~/fedml-server/fedml/logs/
  enable_wandb: true
  wandb_project: fedml_cifar100
  # run_name: fedml_torch_fedavg_mnist_lr
  using_mlops: true
  save_models: True

save_path:
  save_dir: ""
  server_dir_path: "results"

